---
title: "ML 數學經典面試題庫：10 章精選題與解法直覺"
date: 2025-05-17 21:00:00 +0800
categories: [AI 數學基礎]
tags: [面試題, AI 數學, 解題技巧, 直覺, 經典題庫]
---

# ML 數學經典面試題庫：10 章精選題與解法直覺

本章彙整前述 9 章 AI 數學基礎的經典面試題，每章精選 10-15 題，涵蓋計算、推導、直覺解釋與實務應用。每題附上解法提示與常見誤區，幫助你在面試與實戰中脫穎而出。

---

## M1 線性代數快攻

1. **什麼是矩陣的 Rank？如何計算？**
   - *提示：行（或列）線性獨立數量，可用高斯消去法。*
2. **PCA 為何要用特徵分解或 SVD？**
   - *提示：找主成分方向，最大化資料變異。*
3. **Hadamard 乘積與 Kronecker 乘積差異？舉例說明。*
4. **如何判斷一組向量是否為基底？**
   - *提示：檢查線性獨立與張成空間。*
5. **廣播機制在 Numpy 如何運作？**
   - *提示：自動擴展維度，規則？*
6. **特徵值、特徵向量的幾何意義？**
   - *提示：變換後方向不變，縮放倍數。*
7. **SVD 分解的三個矩陣分別代表什麼？**
   - *提示：左奇異向量、奇異值、右奇異向量。*
8. **Rank 與資料降維的關係？**
   - *提示：Rank 決定最大可降維度。*
9. **如何用 Python 求解矩陣 Rank？**
   - *提示：np.linalg.matrix_rank。*
10. **PCA 如何選擇主成分數量？**
    - *提示：累積解釋變異量。*

---

## M2 微積分與連鎖法則

1. **極限的定義與在 ML 中的應用？**
   - *提示：收斂、損失函數極小化。*
2. **導數與梯度有何不同？**
   - *提示：單變數 vs 多變數。*
3. **Jacobian 矩陣在神經網路中的角色？**
   - *提示：多輸入多輸出偏導。*
4. **連鎖法則如何應用於反向傳播？**
   - *提示：逐層傳遞梯度。*
5. **泰勒展開在優化中的意義？**
   - *提示：近似損失曲面，牛頓法。*
6. **如何手算 $f(x) = x^3 + 2x$ 在 $x=2$ 的導數？**
   - *提示：微分規則。*
7. **偏導數與全導數差異？**
   - *提示：多變數函數。*
8. **梯度下降法的數學推導？**
   - *提示：沿負梯度方向更新。*
9. **什麼是鞍點？在優化中有何影響？**
   - *提示：一階導數為零但非極值。*
10. **自動微分的原理？**
    - *提示：鏈式法則、計算圖。*

---

## M3 最適化基石

1. **凸函數的定義與圖形特徵？**
   - *提示：任意兩點連線不高於函數值。*
2. **Lagrange 乘子法的應用場景？**
   - *提示：有約束最適化。*
3. **SGD 與 Adam 差異？何時選用？**
   - *提示：收斂速度、適應性。*
4. **Learning Rate Schedule 有哪些？優缺點？**
   - *提示：Step, Cosine, Warm-up。*
5. **Momentum 如何幫助跳出局部極小？**
   - *提示：累積動量。*
6. **Mini-Batch 訓練的優勢？**
   - *提示：效率、泛化。*
7. **牛頓法與梯度下降法差異？**
   - *提示：二階導數、收斂速度。*
8. **如何選擇最佳學習率？**
   - *提示：實驗、學習率搜尋。*
9. **Adam 優化器的數學公式？**
   - *提示：一階、二階動量。*
10. **SGD 可能遇到哪些問題？**
    - *提示：震盪、收斂慢。*

---

## M4 機率論 Essentials

1. **PMF、PDF、CDF 差異？舉例說明。*
2. **常態分布的數學公式與特性？**
   - *提示：均值、變異數、鐘型曲線。*
3. **條件機率的定義與應用？**
   - *提示：貝氏定理、生成模型。*
4. **全機率公式如何推導？**
   - *提示：分解複雜事件。*
5. **貝氏定理的直覺解釋？**
   - *提示：先驗、後驗。*
6. **獨立事件與條件獨立的差異？**
   - *提示：聯合機率。*
7. **Beta 分布的應用場景？**
   - *提示：機率建模、貝氏推論。*
8. **如何用 Python 產生高斯分布樣本？**
   - *提示：np.random.normal。*
9. **A 與 B 事件獨立，P(A|B)=?**
   - *提示：P(A)。*
10. **機率分布選擇對模型有何影響？**
    - *提示：假設、推論結果。*

---

## M5 統計推論 Toolkit

1. **MLE、MAP、貝氏估計差異？**
2. **t-test、卡方檢定、ANOVA 適用情境？**
3. **Bootstrap 的原理與優缺點？**
4. **交叉驗證如何提升泛化能力？**
5. **p 值的意義與誤用？**
6. **如何計算 95% 信賴區間？**
7. **假設檢定的零假設與對立假設？**
8. **點估計與區間估計的差異？**
9. **何時用非參數檢定？**
10. **如何用 Python 做交叉驗證？**

---

## M6 信息理論 & 損失函數

1. **熵、交叉熵、KL 散度的數學定義與差異？**
2. **KL 散度為何非對稱？有何影響？**
3. **JS 散度的應用場景？**
4. **Softmax + Cross-Entropy 為何好用？**
5. **資訊增益在決策樹的角色？**
6. **如何用 Python 計算交叉熵？**
7. **KL 散度在 VAE 的應用？**
8. **熵越大代表什麼？**
9. **交叉熵損失的梯度推導？**
10. **常見損失函數還有哪些？**

---

## M7 數值計算與穩定性

1. **浮點誤差的來源與影響？**
2. **Underflow/Overflow 如何避免？**
3. **Log-Sum-Exp Trick 的數學推導？**
4. **Gradient Clipping 的原理與應用？**
5. **稀疏矩陣的存儲格式？**
6. **PyTorch 如何支援稀疏運算？**
7. **Softmax 計算時的數值陷阱？**
8. **如何檢查模型訓練時的數值穩定性？**
9. **稀疏矩陣乘法的加速技巧？**
10. **數值不穩定時的 debug 步驟？**

---

## M8 統計學在 ML 實務

1. **Bias-Variance Trade-off 如何可視化？**
2. **MSE、MAE、AUC 各自適用場景？**
3. **置信帶與預測區間的差異？**
4. **高 R² 可能有哪些陷阱？**
5. **如何用交叉驗證評估模型？**
6. **AUC 高但預測效果差的原因？**
7. **如何解釋模型的泛化能力？**
8. **置信帶如何計算？**
9. **混淆矩陣的意義？**
10. **如何用 Python 畫 ROC 曲線？**

---

## M9 機率圖模型 (選讀)

1. **Bayesian Network 如何分解聯合分布？**
2. **MRF 與 BN 差異？**
3. **EM 演算法的 E/M 步驟數學推導？**
4. **HMM 的前向-後向演算法流程？**
5. **GMM 如何自動分群？**
6. **PGM 在 NLP 的應用？**
7. **隱變量模型的直覺解釋？**
8. **EM 為何只保證局部最優？**
9. **如何用 Python 實作 HMM？**
10. **PGM 推理時遇到計算爆炸怎麼辦？**

---

## 解題技巧與常見誤區

- **計算題**：先寫公式再帶數字，避免粗心。
- **推導題**：分步驟寫清楚，標明假設。
- **直覺題**：用圖解、生活例子輔助說明。
- **實作題**：熟悉 numpy、scikit-learn、pytorch 等常用 API。
- **常見誤區**：混淆定義、忽略假設、過度依賴單一指標。

---

## 結語

本題庫涵蓋 AI 數學基礎的經典面試題與解法直覺。建議每題都動手推導、實作與解釋，並多練習口頭表達。祝你面試順利、學習愉快！
